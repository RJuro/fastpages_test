{
  
    
        "post0": {
            "title": "Mandatory Assignment 2",
            "content": "&#160;Part 1: Network Analysis . import networkx as nx import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt sns.set() . !pip install pyvis -qq . from pyvis import network as net . 1. Creating the networks . 1.1 Edge lists cleaning . !wget https://raw.githubusercontent.com/SDS-AAU/SDS-master/master/00_data/network_krackhard/Krack-High-Tec-Attributes.csv !wget https://raw.githubusercontent.com/SDS-AAU/SDS-master/master/00_data/network_krackhard/Krack-High-Tec-edgelist-Advice.txt !wget https://raw.githubusercontent.com/SDS-AAU/SDS-master/master/00_data/network_krackhard/Krack-High-Tec-edgelist-Friendship.txt !wget https://raw.githubusercontent.com/SDS-AAU/SDS-master/master/00_data/network_krackhard/Krack-High-Tec-edgelist-ReportsTo.txt . attributes = pd.read_csv(&#39;Krack-High-Tec-Attributes.csv&#39;) #this is the node list in the M2.1 exercise basically advice = pd.read_csv(&#39;Krack-High-Tec-edgelist-Advice.txt&#39;, delimiter=&quot; s+&quot;, header=None, names=[&#39;ID_ego&#39;,&#39;ID_alter&#39;,&#39;is_edge&#39;]) friendship = pd.read_csv(&#39;Krack-High-Tec-edgelist-Friendship.txt&#39;, delimiter=&quot; s+&quot;, header=None, names=[&#39;ID_ego&#39;,&#39;ID_alter&#39;,&#39;is_edge&#39;]) reports = pd.read_csv(&#39;Krack-High-Tec-edgelist-ReportsTo.txt&#39;,delimiter=&quot; s+&quot;, header=None, names=[&#39;ID_ego&#39;,&#39;ID_alter&#39;,&#39;is_edge&#39;]) . Now that I imported all the relevant files, I will give a quick look to their structure. From the assignment description I know that the connection between nodes is given by the third column of the edges dataframes, which contains a list of 0 and 1. I&#39;ll give a quick look at such dataframes and then filter out the zeros before creating the network. In this way, I keep only the edges that create a direct connection. . advice.head() . ID_ego ID_alter is_edge . 0 1 | 1 | 0 | . 1 1 | 2 | 1 | . 2 1 | 3 | 0 | . 3 1 | 4 | 1 | . 4 1 | 5 | 0 | . I now filter out the 0 in the &#39;is_edge&#39; column in order to keep only the edges that are actually connected to others. After this I&#39;ll create the networks and create a quick (and ugly) plot just to verifiy is there are some major mistakes . advice = advice[advice.is_edge != 0] . advice.head(10) . ID_ego ID_alter is_edge . 1 1 | 2 | 1 | . 3 1 | 4 | 1 | . 7 1 | 8 | 1 | . 15 1 | 16 | 1 | . 17 1 | 18 | 1 | . 20 1 | 21 | 1 | . 26 2 | 6 | 1 | . 27 2 | 7 | 1 | . 41 2 | 21 | 1 | . 42 3 | 1 | 1 | . G_advice = nx.from_pandas_edgelist(advice, source=&#39;ID_ego&#39;, target=&#39;ID_alter&#39;, edge_attr=&#39;is_edge&#39;, create_using=nx.DiGraph) . nx.draw(G_advice, with_labels = False, node_size=10) . I now repeat the same operation for the friendship and report to edge lists . friendship = friendship[friendship.is_edge != 0] . G_friendship = nx.from_pandas_edgelist(friendship, source=&#39;ID_ego&#39;, target=&#39;ID_alter&#39;, edge_attr=&#39;is_edge&#39;, create_using=nx.DiGraph) . nx.draw(G_friendship, with_labels = False, node_size=10) . reports = reports[reports.is_edge != 0] . G_reports = nx.from_pandas_edgelist(reports, source=&#39;ID_ego&#39;, target=&#39;ID_alter&#39;, edge_attr=&#39;is_edge&#39;, create_using=nx.DiGraph) . nx.draw(G_reports, with_labels = False, node_size=10) . 1.2 Setting the attributes . I now work on the attributes. First of all I replace the index automatically generated by pandas with the &#39;ID&#39; so that I can map the results with the edge lists. . attributes.set_index(&#39;ID&#39;,inplace=True) . Then, in order to apply the nodes attributes to the edges, I create dictionary from the attributes df. I use a transpose matrix while creating the dictionary so that the df is inverted and in the dicitonary each ID is associated with all its info (age, tenure, level and dept). . attributes_dict = attributes.T.to_dict() . attributes_dict . {1: {&#39;AGE&#39;: 33.0, &#39;DEPT&#39;: 4.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 9.333}, 2: {&#39;AGE&#39;: 42.0, &#39;DEPT&#39;: 4.0, &#39;LEVEL&#39;: 2.0, &#39;TENURE&#39;: 19.583}, 3: {&#39;AGE&#39;: 40.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 12.75}, 4: {&#39;AGE&#39;: 33.0, &#39;DEPT&#39;: 4.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 7.5}, 5: {&#39;AGE&#39;: 32.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 3.333}, 6: {&#39;AGE&#39;: 59.0, &#39;DEPT&#39;: 1.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 28.0}, 7: {&#39;AGE&#39;: 55.0, &#39;DEPT&#39;: 0.0, &#39;LEVEL&#39;: 1.0, &#39;TENURE&#39;: 30.0}, 8: {&#39;AGE&#39;: 34.0, &#39;DEPT&#39;: 1.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 11.333}, 9: {&#39;AGE&#39;: 62.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 5.417000000000001}, 10: {&#39;AGE&#39;: 37.0, &#39;DEPT&#39;: 3.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 9.25}, 11: {&#39;AGE&#39;: 46.0, &#39;DEPT&#39;: 3.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 27.0}, 12: {&#39;AGE&#39;: 34.0, &#39;DEPT&#39;: 1.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 8.917}, 13: {&#39;AGE&#39;: 48.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 0.25}, 14: {&#39;AGE&#39;: 43.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 2.0, &#39;TENURE&#39;: 10.417}, 15: {&#39;AGE&#39;: 40.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 8.417}, 16: {&#39;AGE&#39;: 27.0, &#39;DEPT&#39;: 4.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 4.667}, 17: {&#39;AGE&#39;: 30.0, &#39;DEPT&#39;: 1.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 12.417}, 18: {&#39;AGE&#39;: 33.0, &#39;DEPT&#39;: 3.0, &#39;LEVEL&#39;: 2.0, &#39;TENURE&#39;: 9.083}, 19: {&#39;AGE&#39;: 32.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 4.833}, 20: {&#39;AGE&#39;: 38.0, &#39;DEPT&#39;: 2.0, &#39;LEVEL&#39;: 3.0, &#39;TENURE&#39;: 11.667}, 21: {&#39;AGE&#39;: 36.0, &#39;DEPT&#39;: 1.0, &#39;LEVEL&#39;: 2.0, &#39;TENURE&#39;: 12.5}} . Now I can attrite the attributes dictionary to the networks so that each node will contain them. I also quickly check that everything is fine by printing them out . nx.set_node_attributes(G_advice, attributes_dict) nx.set_node_attributes(G_friendship, attributes_dict) nx.set_node_attributes(G_reports, attributes_dict) . G_advice.nodes(data=True) . NodeDataView({1: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 9.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 2: {&#39;AGE&#39;: 42.0, &#39;TENURE&#39;: 19.583, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 4.0}, 4: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 7.5, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 8: {&#39;AGE&#39;: 34.0, &#39;TENURE&#39;: 11.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 16: {&#39;AGE&#39;: 27.0, &#39;TENURE&#39;: 4.667, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 18: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 9.083, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 3.0}, 21: {&#39;AGE&#39;: 36.0, &#39;TENURE&#39;: 12.5, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 1.0}, 6: {&#39;AGE&#39;: 59.0, &#39;TENURE&#39;: 28.0, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 7: {&#39;AGE&#39;: 55.0, &#39;TENURE&#39;: 30.0, &#39;LEVEL&#39;: 1.0, &#39;DEPT&#39;: 0.0}, 3: {&#39;AGE&#39;: 40.0, &#39;TENURE&#39;: 12.75, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 9: {&#39;AGE&#39;: 62.0, &#39;TENURE&#39;: 5.417000000000001, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 10: {&#39;AGE&#39;: 37.0, &#39;TENURE&#39;: 9.25, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 3.0}, 11: {&#39;AGE&#39;: 46.0, &#39;TENURE&#39;: 27.0, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 3.0}, 12: {&#39;AGE&#39;: 34.0, &#39;TENURE&#39;: 8.917, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 14: {&#39;AGE&#39;: 43.0, &#39;TENURE&#39;: 10.417, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 2.0}, 17: {&#39;AGE&#39;: 30.0, &#39;TENURE&#39;: 12.417, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 20: {&#39;AGE&#39;: 38.0, &#39;TENURE&#39;: 11.667, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 5: {&#39;AGE&#39;: 32.0, &#39;TENURE&#39;: 3.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 13: {&#39;AGE&#39;: 48.0, &#39;TENURE&#39;: 0.25, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 19: {&#39;AGE&#39;: 32.0, &#39;TENURE&#39;: 4.833, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 15: {&#39;AGE&#39;: 40.0, &#39;TENURE&#39;: 8.417, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}}) . G_friendship.nodes(data=True) . NodeDataView({1: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 9.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 2: {&#39;AGE&#39;: 42.0, &#39;TENURE&#39;: 19.583, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 4.0}, 4: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 7.5, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 8: {&#39;AGE&#39;: 34.0, &#39;TENURE&#39;: 11.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 12: {&#39;AGE&#39;: 34.0, &#39;TENURE&#39;: 8.917, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 16: {&#39;AGE&#39;: 27.0, &#39;TENURE&#39;: 4.667, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 18: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 9.083, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 3.0}, 21: {&#39;AGE&#39;: 36.0, &#39;TENURE&#39;: 12.5, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 1.0}, 3: {&#39;AGE&#39;: 40.0, &#39;TENURE&#39;: 12.75, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 14: {&#39;AGE&#39;: 43.0, &#39;TENURE&#39;: 10.417, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 2.0}, 19: {&#39;AGE&#39;: 32.0, &#39;TENURE&#39;: 4.833, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 17: {&#39;AGE&#39;: 30.0, &#39;TENURE&#39;: 12.417, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 5: {&#39;AGE&#39;: 32.0, &#39;TENURE&#39;: 3.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 9: {&#39;AGE&#39;: 62.0, &#39;TENURE&#39;: 5.417000000000001, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 11: {&#39;AGE&#39;: 46.0, &#39;TENURE&#39;: 27.0, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 3.0}, 6: {&#39;AGE&#39;: 59.0, &#39;TENURE&#39;: 28.0, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 7: {&#39;AGE&#39;: 55.0, &#39;TENURE&#39;: 30.0, &#39;LEVEL&#39;: 1.0, &#39;DEPT&#39;: 0.0}, 10: {&#39;AGE&#39;: 37.0, &#39;TENURE&#39;: 9.25, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 3.0}, 20: {&#39;AGE&#39;: 38.0, &#39;TENURE&#39;: 11.667, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 13: {&#39;AGE&#39;: 48.0, &#39;TENURE&#39;: 0.25, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 15: {&#39;AGE&#39;: 40.0, &#39;TENURE&#39;: 8.417, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}}) . G_reports.nodes(data=True) . NodeDataView({1: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 9.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 2: {&#39;AGE&#39;: 42.0, &#39;TENURE&#39;: 19.583, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 4.0}, 7: {&#39;AGE&#39;: 55.0, &#39;TENURE&#39;: 30.0, &#39;LEVEL&#39;: 1.0, &#39;DEPT&#39;: 0.0}, 3: {&#39;AGE&#39;: 40.0, &#39;TENURE&#39;: 12.75, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 14: {&#39;AGE&#39;: 43.0, &#39;TENURE&#39;: 10.417, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 2.0}, 4: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 7.5, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 5: {&#39;AGE&#39;: 32.0, &#39;TENURE&#39;: 3.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 6: {&#39;AGE&#39;: 59.0, &#39;TENURE&#39;: 28.0, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 21: {&#39;AGE&#39;: 36.0, &#39;TENURE&#39;: 12.5, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 1.0}, 8: {&#39;AGE&#39;: 34.0, &#39;TENURE&#39;: 11.333, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 9: {&#39;AGE&#39;: 62.0, &#39;TENURE&#39;: 5.417000000000001, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 10: {&#39;AGE&#39;: 37.0, &#39;TENURE&#39;: 9.25, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 3.0}, 18: {&#39;AGE&#39;: 33.0, &#39;TENURE&#39;: 9.083, &#39;LEVEL&#39;: 2.0, &#39;DEPT&#39;: 3.0}, 11: {&#39;AGE&#39;: 46.0, &#39;TENURE&#39;: 27.0, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 3.0}, 12: {&#39;AGE&#39;: 34.0, &#39;TENURE&#39;: 8.917, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 13: {&#39;AGE&#39;: 48.0, &#39;TENURE&#39;: 0.25, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 15: {&#39;AGE&#39;: 40.0, &#39;TENURE&#39;: 8.417, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 16: {&#39;AGE&#39;: 27.0, &#39;TENURE&#39;: 4.667, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 4.0}, 17: {&#39;AGE&#39;: 30.0, &#39;TENURE&#39;: 12.417, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 1.0}, 19: {&#39;AGE&#39;: 32.0, &#39;TENURE&#39;: 4.833, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}, 20: {&#39;AGE&#39;: 38.0, &#39;TENURE&#39;: 11.667, &#39;LEVEL&#39;: 3.0, &#39;DEPT&#39;: 2.0}}) . 2. Analysis . 2.A Network level characteristics. Find the overal network level of: . Density | Transistivity (Clustering Coefficient) | Reciprocity | . Density . The density of a measure represents the share of all connected to all possible connections in the network. If density is 1 means all connections, while 0 means no connections . nx.density(G_advice) . 0.4523809523809524 . nx.density(G_friendship) . 0.24285714285714285 . nx.density(G_reports) . 0.047619047619047616 . Transitivity . Transistivity, also called the Clustering Cefficient indicates how much the network tends to be locally clustered. . nx.transitivity(G_advice) . 0.4651600753295669 . nx.transitivity(G_friendship) . 0.27581863979848864 . nx.transitivity(G_reports) . 0 . Reciprocity . nx.reciprocity(G_advice) . 0.47368421052631576 . nx.reciprocity(G_friendship) . 0.45098039215686275 . nx.reciprocity(G_reports) . 0.0 . Are relationships like friendship and advice giving usually reciprocal? . By looking at the reciprocity rates it&#39;s possible to notice how for both advice giving and friendship, more than half of the times the relantinship is not considered reciprocal. The rates in friendship (45%) is lower that the one in advice_giving (47%), which means that managers are more likely to have a reciprocal relationship in advice giving/seeking rather to be friends. But this figure is still less that the half. . Are friends of your friends also your friends? . That is measured by the share of closed triplets. The result for friendhsip implies that there is a 27% chance that a friend of a friend is also your friend. So the chance that friends of friends are also someone&#39;s friends are close to 1/4 . Are the employees generally more likely to be in a friendship or advice-seeking relationship? emplyees are more likely to be in an advice-seeking relationship (density at 45%) rather than in a friendship (density at 24,2%). So it seems like that at this company people are more interested in climb the business ladder rather than get to know thei co-workers . 2.B Node level characteristics . Centrality . Centralities can be easily created on node level various centrality algorithms. Since this network is directed we have to split the centrality between in centrality (to which specific person people generally go) and out centrality (to which people a specific person generally goes). Since we have to find out who is the most popular in the network (meaning the person to whom peple go to) I&#39;ll consider the inner_degree of centrality. . centrality_dgr_advice = nx.in_degree_centrality(G_advice) centrality_dgr_friendship = nx.in_degree_centrality(G_friendship) centrality_dgr_reports = nx.in_degree_centrality(G_reports) . I can quickly print the result to check and then I&#39;ll add the values to our initial dataframe so that I can filter out who is the most popular in the network according to the criteris. Since we have only 20 inputs it would be easy to do it also without lines of code, but I add the data to the df anyway. . centrality_dgr_advice . {1: 0.65, 2: 0.9, 3: 0.25, 4: 0.4, 5: 0.25, 6: 0.5, 7: 0.65, 8: 0.5, 9: 0.2, 10: 0.45, 11: 0.55, 12: 0.35000000000000003, 13: 0.2, 14: 0.5, 15: 0.2, 16: 0.4, 17: 0.45, 18: 0.75, 19: 0.2, 20: 0.4, 21: 0.75} . cent_friendship_df = pd.DataFrame({&#39;ID&#39;: centrality_dgr_friendship.keys(), &#39;centr_dg&#39;: centrality_dgr_friendship.values()}) . cent_friendship_df[&quot;Relation&quot;] = &quot;friendship&quot; . cent_advice_df = pd.DataFrame({&#39;ID&#39;: centrality_dgr_advice.keys(), &#39;centr_dg&#39;: centrality_dgr_advice.values()}) . cent_advice_df[&quot;Relation&quot;] = &quot;advice&quot; . cent_report_df = pd.DataFrame({&#39;ID&#39;: centrality_dgr_reports.keys(), &#39;centr_dg&#39;: centrality_dgr_reports.values()}) . cent_report_df[&quot;Relation&quot;] = &quot;report_to&quot; . Who is most popular in the networks. Who is the most wanted friend, and advice giver? . After creating the datafram I now merge them with the Attributes one to find who is the most wanted friend and the most wanted advice giver . centrality_friendship_df = pd.merge(cent_friendship_df, attributes, on = &quot;ID&quot;, how=&quot;left&quot;) . centrality_friendship_df.sort_values(&quot;centr_dg&quot;, ascending=False) . ID centr_dg Relation AGE TENURE LEVEL DEPT . 1 2 | 0.50 | friendship | 42 | 19.583 | 2 | 4 | . 0 1 | 0.40 | friendship | 33 | 9.333 | 3 | 4 | . 4 12 | 0.40 | friendship | 34 | 8.917 | 3 | 1 | . 14 11 | 0.30 | friendship | 46 | 27.000 | 3 | 3 | . 13 9 | 0.30 | friendship | 62 | 5.417 | 3 | 2 | . 12 5 | 0.30 | friendship | 32 | 3.333 | 3 | 2 | . 11 17 | 0.30 | friendship | 30 | 12.417 | 3 | 1 | . 9 14 | 0.25 | friendship | 43 | 10.417 | 2 | 2 | . 10 19 | 0.25 | friendship | 32 | 4.833 | 3 | 2 | . 8 3 | 0.25 | friendship | 40 | 12.750 | 3 | 2 | . 7 21 | 0.25 | friendship | 36 | 12.500 | 2 | 1 | . 3 8 | 0.25 | friendship | 34 | 11.333 | 3 | 1 | . 2 4 | 0.25 | friendship | 33 | 7.500 | 3 | 4 | . 6 18 | 0.20 | friendship | 33 | 9.083 | 2 | 3 | . 5 16 | 0.20 | friendship | 27 | 4.667 | 3 | 4 | . 20 15 | 0.20 | friendship | 40 | 8.417 | 3 | 2 | . 16 7 | 0.15 | friendship | 55 | 30.000 | 1 | 0 | . 18 20 | 0.15 | friendship | 38 | 11.667 | 3 | 2 | . 15 6 | 0.10 | friendship | 59 | 28.000 | 3 | 1 | . 17 10 | 0.05 | friendship | 37 | 9.250 | 3 | 3 | . 19 13 | 0.05 | friendship | 48 | 0.250 | 3 | 2 | . I now do the same for friendship . centrality_advice_df = pd.merge(cent_advice_df, attributes, on = &quot;ID&quot;, how=&quot;left&quot;) . centrality_advice_df.sort_values(&quot;centr_dg&quot;, ascending=False) . ID centr_dg Relation AGE TENURE LEVEL DEPT . 1 2 | 0.90 | advice | 42 | 19.583 | 2 | 4 | . 5 18 | 0.75 | advice | 33 | 9.083 | 2 | 3 | . 6 21 | 0.75 | advice | 36 | 12.500 | 2 | 1 | . 0 1 | 0.65 | advice | 33 | 9.333 | 3 | 4 | . 8 7 | 0.65 | advice | 55 | 30.000 | 1 | 0 | . 12 11 | 0.55 | advice | 46 | 27.000 | 3 | 3 | . 3 8 | 0.50 | advice | 34 | 11.333 | 3 | 1 | . 7 6 | 0.50 | advice | 59 | 28.000 | 3 | 1 | . 14 14 | 0.50 | advice | 43 | 10.417 | 2 | 2 | . 15 17 | 0.45 | advice | 30 | 12.417 | 3 | 1 | . 11 10 | 0.45 | advice | 37 | 9.250 | 3 | 3 | . 2 4 | 0.40 | advice | 33 | 7.500 | 3 | 4 | . 4 16 | 0.40 | advice | 27 | 4.667 | 3 | 4 | . 16 20 | 0.40 | advice | 38 | 11.667 | 3 | 2 | . 13 12 | 0.35 | advice | 34 | 8.917 | 3 | 1 | . 9 3 | 0.25 | advice | 40 | 12.750 | 3 | 2 | . 17 5 | 0.25 | advice | 32 | 3.333 | 3 | 2 | . 19 19 | 0.20 | advice | 32 | 4.833 | 3 | 2 | . 10 9 | 0.20 | advice | 62 | 5.417 | 3 | 2 | . 18 13 | 0.20 | advice | 48 | 0.250 | 3 | 2 | . 20 15 | 0.20 | advice | 40 | 8.417 | 3 | 2 | . From the sorted dataframes it&#39;s possible to see how the person with ID 2 is the most popular in the network since it has the higest centrality for both advice and friendship. This data makes sense since he covers a vice president position . Are managers in higher hirarchy more popular as friend, and advice giver? . A reminder. LEVEL: The level in the corporate hierarchy (coded 1,2 and 3; 1 = CEO, 2 = Vice President, 3 = manager) . centrality_advice_df.groupby([&quot;Relation&quot;, &quot;LEVEL&quot;])[&quot;centr_dg&quot;].mean() . Relation LEVEL advice 1 0.650000 2 0.725000 3 0.371875 Name: centr_dg, dtype: float64 . centrality_friendship_df.groupby([&quot;Relation&quot;, &quot;LEVEL&quot;])[&quot;centr_dg&quot;].mean() . Relation LEVEL friendship 1 0.150000 2 0.300000 3 0.234375 Name: centr_dg, dtype: float64 . So we can see that it&#39;s not true that managers in higher position are more popular as friends and advice giver. We can see how Vice Presidents score higher on both friendship and advice giving. Again, this data makes sense since VPs are more likely to have more interactions with both higher and lower level managers, while the CEO has less chances to do so. It is interesting to notice how a lot of managaers want to become friend with the CEO, while very few look for advice from him . &#160;2C: Relational Characteristics: Answer the following questions: . Are managers from the same 1. department, or on the same 2. hirarchy, 3. age, or 4. tenuere more likely to become friends or give advice? . To answer this question I&#39;ll take into account assortiativity. In a nutshell, it measures if two nodes that share certain characteristics ahve a higher or lower probability to be connected. . So I will run this analysis on the 4 categories and see if this creates more possiblities for them to be connected . I will start my analysis with friendship . nx.attribute_assortativity_coefficient(G_friendship, &#39;DEPT&#39;) . 0.15908798145047023 . nx.attribute_assortativity_coefficient(G_friendship, &#39;LEVEL&#39;) . 0.18750000000000006 . nx.attribute_assortativity_coefficient(G_friendship, &#39;AGE&#39;) . -0.031914893617021274 . nx.attribute_assortativity_coefficient(G_friendship, &#39;TENURE&#39;) . -0.05271678640089042 . From the results above we can see that: . People from the same department are more likely to be friend with people from the same department rather others | People at the same level tend to be friend with their peers | Age seems to have a negative influence on the possibility to be friends, meaning that people at the same age are less likely to befriended, which is an interesting and unexpected finding | Also the amount of years spend within the company seems to have a negative influence on the possibility to be friends, so people that just joined the company are less likely to be friends with their peers | . I now proceed with advice giving . nx.attribute_assortativity_coefficient(G_advice, &#39;DEPT&#39;) . 0.02390296111309304 . nx.attribute_assortativity_coefficient(G_advice, &#39;LEVEL&#39;) . 0.008073817762398955 . nx.attribute_assortativity_coefficient(G_advice, &#39;AGE&#39;) . -0.03149370125974804 . nx.attribute_assortativity_coefficient(G_advice, &#39;TENURE&#39;) . -0.045709982040437976 . From the results above we can see that when it comes to advice: . People ask slightly more frequently for advice to people in the same department | The level doesn&#39;t seem to count too much, so manaagers are more likely to ask fro advice to both higher and lower ranks | People of the same age are less likely to ask advice to their peers | And also people that spend a similat amount of years in the company are slightly less likely to ask advice to each other | . Are friends more likely to give each others advice? . To answer this question we need the total number of friends (which I have already since it is the first df when is_edge = 1) and the number of the people that ask advice to their friends, which I need to find. . Then I will calculate a new df starting from the friendship edge list where I will find the not friends, and repeat the same procedure. . friendship.head(2) . ID_ego ID_alter is_edge . 1 1 | 2 | 1 | . 3 1 | 4 | 1 | . G_friendship.edges . OutEdgeView([(1, 2), (1, 4), (1, 8), (1, 12), (1, 16), (2, 1), (2, 18), (2, 21), (4, 1), (4, 2), (4, 8), (4, 12), (4, 16), (4, 17), (8, 4), (12, 1), (12, 4), (12, 17), (12, 21), (16, 1), (16, 2), (18, 2), (21, 2), (21, 12), (21, 17), (21, 18), (3, 14), (3, 19), (14, 7), (14, 15), (19, 1), (19, 2), (19, 3), (19, 5), (19, 11), (19, 12), (19, 14), (19, 15), (19, 20), (17, 1), (17, 2), (17, 3), (17, 4), (17, 5), (17, 6), (17, 7), (17, 8), (17, 9), (17, 10), (17, 11), (17, 12), (17, 14), (17, 15), (17, 16), (17, 19), (17, 20), (17, 21), (5, 2), (5, 9), (5, 11), (5, 14), (5, 17), (5, 19), (5, 21), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 8), (11, 9), (11, 12), (11, 13), (11, 15), (11, 17), (11, 18), (11, 19), (6, 2), (6, 7), (6, 9), (6, 12), (6, 17), (6, 21), (10, 3), (10, 5), (10, 8), (10, 9), (10, 12), (10, 16), (10, 20), (20, 11), (20, 18), (13, 5), (13, 11), (15, 1), (15, 3), (15, 5), (15, 6), (15, 9), (15, 11), (15, 14), (15, 19)]) . total_friends = friendship[&quot;is_edge&quot;].value_counts() . friends_advice_number = 0 for i in G_friendship.edges(): if i in G_advice.edges(): friends_advice_number += 1 . print(friends_advice_number/total_friends) . 1 0.588235 Name: is_edge, dtype: float64 . I now do the same for no friends . no_friendship = pd.read_csv(&#39;Krack-High-Tec-edgelist-Friendship.txt&#39;, delimiter=&quot; s+&quot;, header=None, names=[&#39;ID_ego&#39;,&#39;ID_alter&#39;,&#39;is_edge&#39;]) . no_friendship = no_friendship[no_friendship.is_edge == 0] . G_no_friendship = nx.from_pandas_edgelist(no_friendship, source=&#39;ID_ego&#39;, target=&#39;ID_alter&#39;, edge_attr=&#39;is_edge&#39;, create_using=nx.DiGraph) . total_no_friends = no_friendship[&#39;is_edge&#39;].value_counts() . no_friends_advice_number = 0 for i in G_no_friendship.edges(): if i in G_advice.edges(): no_friends_advice_number += 1 . print(no_friends_advice_number/total_no_friends) . 0 0.383481 Name: is_edge, dtype: float64 . So we can see how the 58.8% of friends give each other advice, while only 38.3% of no friends give each other advice. . 3. Visualization . At first I will import the required packages for visualization . import holoviews as hv from holoviews import opts hv.extension(&#39;bokeh&#39;) from bokeh.plotting import show # Setting the default figure size a bit larger defaults = dict(width=750, height=750, padding=0.1, xaxis=None, yaxis=None) hv.opts.defaults( opts.EdgePaths(**defaults), opts.Graph(**defaults), opts.Nodes(**defaults)) . &lt;/img&gt; &lt;/img&gt; G_layout_friendship = nx.layout.kamada_kawai_layout(G_friendship) . g_plot_friendship = hv.Graph.from_networkx(G_friendship, G_layout_friendship).opts(tools=[&#39;hover&#39;], directed=True, edge_alpha=0.25, #node_size = &#39;cent_degree&#39;, node_color=&#39;AGE&#39;, cmap=&#39;Set2&#39;, legend_position=&#39;left&#39; ) . show(hv.render(g_plot_friendship)) . The first graph shows the network filtered by &#39;AGE&#39; and in relation to the centrality level of the nodes. . G_layout_advice = nx.layout.kamada_kawai_layout(G_advice) . g_plot_advice = hv.Graph.from_networkx(G_advice, G_layout_advice).opts(tools=[&#39;hover&#39;], directed=True, edge_alpha=0.25, node_color=&#39;LEVEL&#39;, cmap=&#39;Set2&#39;, legend_position=&#39;right&#39; ) . show(hv.render(g_plot_advice)) . The second graph takes into account the advice network and it&#39;s filtered by LEVEL. During our analysis before we found out that the most popular person in the network is the vie president with ID 2. Here we can see him at the center of the network. Also the LEVEL filtering allows us to see how many mangaers there are and how 1 vp out 4 seems to be more at the edges of the network . G_layout_reports = nx.layout.kamada_kawai_layout(G_reports) . g_plot_reports = hv.Graph.from_networkx(G_advice, G_layout_reports).opts(tools=[&#39;hover&#39;], directed=True, edge_alpha=0.25, node_color=&#39;LEVEL&#39;, cmap=&#39;Set3&#39;, legend_position=&#39;right&#39; ) . show(hv.render(g_plot_reports)) . Finally, this graph shows how actuallt the structure of the company seems to be really compartementalized. Even thought some of the Level 3 nodes seem to report directly to the CEO . Part 2: NLP: Hate-speech and offensive language on Twitter . for the df keep in mind that class denotes: 0 - hate speech, 1 - offensive language, 2 - neither . 1. Preprocessing and vectorizaion. . I will start the preprocessing by importing the required packages. I will use a mix of functions from NLTK and also the twitter prepocessor, which will allow me to reduce fastly some of the elements typical of twitter (I can choose from URLs, Hashtags, Mentions, Reserved words (RT, FAV), Emojis, Smileys, Numbers) . from nltk.tokenize import TweetTokenizer tknzr = TweetTokenizer() . import nltk #this part is needed on colab. nltk.download(&#39;punkt&#39;) nltk.download(&#39;stopwords&#39;) . [nltk_data] Downloading package punkt to /root/nltk_data... [nltk_data] Unzipping tokenizers/punkt.zip. [nltk_data] Downloading package stopwords to /root/nltk_data... [nltk_data] Unzipping corpora/stopwords.zip. . True . import spacy nlp = spacy.load(&quot;en&quot;) . !pip install tweet-preprocessor . Collecting tweet-preprocessor Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl Installing collected packages: tweet-preprocessor Successfully installed tweet-preprocessor-0.6.0 . import preprocessor as p . data = pd.read_csv(&#39;https://github.com/SDS-AAU/SDS-2020/raw/master/M2/assignments/data/twitter_hate.zip&#39;) . data.head (25) . Unnamed: 0 class tweet . 0 0 | 2 | !!! RT @mayasolovely: As a woman you shouldn&#39;t... | . 1 1 | 1 | !!!!! RT @mleew17: boy dats cold...tyga dwn ba... | . 2 2 | 1 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby... | . 3 3 | 1 | !!!!!!!!! RT @C_G_Anderson: @viva_based she lo... | . 4 4 | 1 | !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you... | . 5 5 | 1 | !!!!!!!!!!!!!!!!!!&quot;@T_Madison_x: The shit just... | . 6 6 | 1 | !!!!!!&quot;@__BrighterDays: I can not just sit up ... | . 7 7 | 1 | !!!!&amp;#8220;@selfiequeenbri: cause I&#39;m tired of... | . 8 8 | 1 | &quot; &amp;amp; you might not get ya bitch back &amp;amp; ... | . 9 9 | 1 | &quot; @rhythmixx_ :hobbies include: fighting Maria... | . 10 10 | 1 | &quot; Keeks is a bitch she curves everyone &quot; lol I... | . 11 11 | 1 | &quot; Murda Gang bitch its Gang Land &quot; | . 12 12 | 1 | &quot; So hoes that smoke are losers ? &quot; yea ... go... | . 13 13 | 1 | &quot; bad bitches is the only thing that i like &quot; | . 14 14 | 1 | &quot; bitch get up off me &quot; | . 15 15 | 1 | &quot; bitch nigga miss me with it &quot; | . 16 16 | 1 | &quot; bitch plz whatever &quot; | . 17 17 | 1 | &quot; bitch who do you love &quot; | . 18 18 | 1 | &quot; bitches get cut off everyday B &quot; | . 19 19 | 1 | &quot; black bottle &amp;amp; a bad bitch &quot; | . 20 20 | 1 | &quot; broke bitch cant tell me nothing &quot; | . 21 21 | 1 | &quot; cancel that bitch like Nino &quot; | . 22 22 | 1 | &quot; cant you see these hoes wont change &quot; | . 23 23 | 1 | &quot; fuck no that bitch dont even suck dick &quot; &amp;#1... | . 24 24 | 1 | &quot; got ya bitch tip toeing on my hardwood floor... | . By giving a quick look at the dataframe I can see that hashtags are often referring to number, which won&#39;t be beneficial for the analysis. So I will start the analysis without considering them. Also, mentions seems to refer to random users with pretty much random names, therefore they will be excluded as well. I will start with those and then see if other cleaning is needed . p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.RESERVED, p.OPT.MENTION, p.OPT.HASHTAG) . I will now test if the cleaning works or not . p.clean(&#39;RT ðŸ¤¬ this is a tweet #yeah # no @CBS http://something.dk&#39;) . &#39;this is a tweet no&#39; . The prepocessor seems to work. I will now try to check how it works on my df . data_try = pd.DataFrame ([p.clean(tweet) for tweet in data[&#39;tweet&#39;][:10]], columns = [&#39;clean&#39;]) . data_try[&#39;no clean&#39;] = data [&#39;tweet&#39;][:10] . data_try . clean no clean . 0 !!! RT : As a woman you shouldn&#39;t complain abo... | !!! RT @mayasolovely: As a woman you shouldn&#39;t... | . 1 !!!!! RT : boy dats cold...tyga dwn bad for cu... | !!!!! RT @mleew17: boy dats cold...tyga dwn ba... | . 2 !!!!!!! RT Dawg!!!! RT : You ever fuck a bitch... | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby... | . 3 !!!!!!!!! RT : she look like a tranny | !!!!!!!!! RT @C_G_Anderson: @viva_based she lo... | . 4 !!!!!!!!!!!!! RT : The shit you hear about me ... | !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you... | . 5 !!!!!!!!!!!!!!!!!!&quot;: The shit just blows me..c... | !!!!!!!!!!!!!!!!!!&quot;@T_Madison_x: The shit just... | . 6 !!!!!!&quot;: I can not just sit up and HATE on ano... | !!!!!!&quot;@__BrighterDays: I can not just sit up ... | . 7 !!!!&amp;;: cause I&#39;m tired of you big bitches com... | !!!!&amp;#8220;@selfiequeenbri: cause I&#39;m tired of... | . 8 &quot; &amp;amp; you might not get ya bitch back &amp;amp; ... | &quot; &amp;amp; you might not get ya bitch back &amp;amp; ... | . 9 &quot; :hobbies include: fighting Mariam&quot; bitch | &quot; @rhythmixx_ :hobbies include: fighting Maria... | . It seems like numbers, hashtags and mention are correcly removed. However, RT was succesfully removed in the try but not on the real tweets. I will apply this initial filter and continue to make it more specific . data[&#39;tweet_clean&#39;] = [p.clean(tweet) for tweet in data[&#39;tweet&#39;]] . data . Unnamed: 0 class tweet tweet_clean . 0 0 | 2 | !!! RT @mayasolovely: As a woman you shouldn&#39;t... | !!! RT : As a woman you shouldn&#39;t complain abo... | . 1 1 | 1 | !!!!! RT @mleew17: boy dats cold...tyga dwn ba... | !!!!! RT : boy dats cold...tyga dwn bad for cu... | . 2 2 | 1 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby... | !!!!!!! RT Dawg!!!! RT : You ever fuck a bitch... | . 3 3 | 1 | !!!!!!!!! RT @C_G_Anderson: @viva_based she lo... | !!!!!!!!! RT : she look like a tranny | . 4 4 | 1 | !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you... | !!!!!!!!!!!!! RT : The shit you hear about me ... | . ... ... | ... | ... | ... | . 24778 24778 | 1 | you&#39;s a muthaf***in lie &amp;#8220;@LifeAsKing: @2... | you&#39;s a muthaf***in lie &amp;;: right! His TL is t... | . 24779 24779 | 2 | you&#39;ve gone and broke the wrong heart baby, an... | you&#39;ve gone and broke the wrong heart baby, an... | . 24780 24780 | 1 | young buck wanna eat!!.. dat nigguh like I ain... | young buck wanna eat!!.. dat nigguh like I ain... | . 24781 24781 | 1 | youu got wild bitches tellin you lies | youu got wild bitches tellin you lies | . 24782 24782 | 2 | ~~Ruffled | Ntac Eileen Dahlia - Beautiful col... | ~~Ruffled | Ntac Eileen Dahlia - Beautiful col... | . 24783 rows Ã— 4 columns . I will now address the problem related with RT and remove that word manually. Also, I will remove the punctuation. I am going to use Spacy for the other operations. I&#39;m aware that it is efficient in removing punctuation, but I had some problems with this in previous excercises so I&#39;ll remove the punctuation to begin with. . from string import punctuation . cleanup_elements = list(set(punctuation)) cleanup_elements.append(&quot;RT&quot;) . for ele in cleanup_elements: data[&quot;tweet_clean&quot;] = [tweet.replace(ele, &quot;&quot;) for tweet in data[&quot;tweet_clean&quot;]] . data.head(10) . Unnamed: 0 class tweet tweet_clean . 0 0 | 2 | !!! RT @mayasolovely: As a woman you shouldn&#39;t... | As a woman you shouldnt complain about clea... | . 1 1 | 1 | !!!!! RT @mleew17: boy dats cold...tyga dwn ba... | boy dats coldtyga dwn bad for cuffin dat ho... | . 2 2 | 1 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby... | Dawg You ever fuck a bitch and she start t... | . 3 3 | 1 | !!!!!!!!! RT @C_G_Anderson: @viva_based she lo... | she look like a tranny | . 4 4 | 1 | !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you... | The shit you hear about me might be true or... | . 5 5 | 1 | !!!!!!!!!!!!!!!!!!&quot;@T_Madison_x: The shit just... | The shit just blows meclaim you so faithful a... | . 6 6 | 1 | !!!!!!&quot;@__BrighterDays: I can not just sit up ... | I can not just sit up and HATE on another bit... | . 7 7 | 1 | !!!!&amp;#8220;@selfiequeenbri: cause I&#39;m tired of... | cause Im tired of you big bitches coming for ... | . 8 8 | 1 | &quot; &amp;amp; you might not get ya bitch back &amp;amp; ... | amp you might not get ya bitch back amp thats... | . 9 9 | 1 | &quot; @rhythmixx_ :hobbies include: fighting Maria... | hobbies include fighting Mariam bitch | . As we can see in the df, the Twitter preprosessor worked as intended, removing the twitter-related elements. Plus, the &#39;RT&#39; problem as been addressed. Now I will use spacy to further clean and minimized the tweets textual data. To begin with, I start by creating a new column in the data frame to check how spacy will tokenize the tweets . data[&#39;tweet_nlp&#39;] = [nlp(tweet) for tweet in data[&#39;tweet_clean&#39;]] . data.head() . Unnamed: 0 class tweet tweet_clean tweet_nlp . 0 0 | 2 | !!! RT @mayasolovely: As a woman you shouldn&#39;t... | As a woman you shouldnt complain about clea... | ( , As, a, woman, you, should, nt, complain,... | . 1 1 | 1 | !!!!! RT @mleew17: boy dats cold...tyga dwn ba... | boy dats coldtyga dwn bad for cuffin dat ho... | ( , boy, dats, coldtyga, dwn, bad, for, cuff... | . 2 2 | 1 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby... | Dawg You ever fuck a bitch and she start t... | ( , Dawg, , You, ever, fuck, a, bitch, and,... | . 3 3 | 1 | !!!!!!!!! RT @C_G_Anderson: @viva_based she lo... | she look like a tranny | ( , she, look, like, a, tranny) | . 4 4 | 1 | !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you... | The shit you hear about me might be true or... | ( , The, shit, you, hear, about, me, might, ... | . data.loc[1,&#39;tweet_nlp&#39;] . boy dats coldtyga dwn bad for cuffin dat hoe in the 1st place . I see that there are other elements that require being addressed. First the tweets use a lot of punctuations, especially exclamation points. Normally an exclamation point can be beneficial, but in this df it seems like they are spammed quite a lot, so I decided to remove them. Also, I am going to make all the text lower case. Finally, I will normalize the text, removing any plural/singulal and first person/third person distinction. The last question to ask is if it&#39;s worth it or not to keep the verbs. Normally, I would exclude them. But in this case some of the verbs can be actually a good metric to target the aggression level of the language, so I&#39;ll keep them. . To make this analysis become real, I will use spacy. The function below is set to normalize and set to lower case the tweets (modifying and keeping only nouns, pronouns, adjectives, adverbs and verbs) and finally removing punctuation. . tokens = [] for tweet in nlp.pipe(data[&#39;tweet_clean&#39;]): tweet_tok = [token.lemma_.lower() for token in tweet if token.pos_ in [&#39;NOUN&#39;, &#39;PROPN&#39;, &#39;ADJ&#39;, &#39;ADV&#39;, &#39;VERB&#39;] and not token.is_stop] tokens.append(tweet_tok) . Spacy has done a great job in filtering the tokens. I will now add both the token list and the tokens as a string to the dataframe so to have all the info that I need for the next steps in the df . data[&#39;tokens&#39;] = tokens . data[&quot;token_string&quot;] = data[&quot;tokens&quot;].map(lambda row: &quot; &quot;.join(row)) . data.head(10) . Unnamed: 0 class tweet tweet_clean tweet_nlp tokens token_string . 0 0 | 2 | !!! RT @mayasolovely: As a woman you shouldn&#39;t... | As a woman you shouldnt complain about clea... | ( , As, a, woman, you, should, nt, complain,... | [woman, complain, clean, house, amp, man, trash] | woman complain clean house amp man trash | . 1 1 | 1 | !!!!! RT @mleew17: boy dats cold...tyga dwn ba... | boy dats coldtyga dwn bad for cuffin dat ho... | ( , boy, dats, coldtyga, dwn, bad, for, cuff... | [boy, dats, coldtyga, dwn, bad, cuffin, hoe, 1... | boy dats coldtyga dwn bad cuffin hoe 1st place | . 2 2 | 1 | !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby... | Dawg You ever fuck a bitch and she start t... | ( , Dawg, , You, ever, fuck, a, bitch, and,... | [dawg, fuck, bitch, start, cry, confuse, shit] | dawg fuck bitch start cry confuse shit | . 3 3 | 1 | !!!!!!!!! RT @C_G_Anderson: @viva_based she lo... | she look like a tranny | ( , she, look, like, a, tranny) | [look, tranny] | look tranny | . 4 4 | 1 | !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you... | The shit you hear about me might be true or... | ( , The, shit, you, hear, about, me, might, ... | [shit, hear, true, faker, bitch, tell] | shit hear true faker bitch tell | . 5 5 | 1 | !!!!!!!!!!!!!!!!!!&quot;@T_Madison_x: The shit just... | The shit just blows meclaim you so faithful a... | ( , The, shit, just, blows, meclaim, you, so, ... | [shit, blow, meclaim, faithful, fuck, hoe] | shit blow meclaim faithful fuck hoe | . 6 6 | 1 | !!!!!!&quot;@__BrighterDays: I can not just sit up ... | I can not just sit up and HATE on another bit... | ( , I, can, not, just, sit, up, and, HATE, on,... | [sit, hate, bitch, get, shit, go] | sit hate bitch get shit go | . 7 7 | 1 | !!!!&amp;#8220;@selfiequeenbri: cause I&#39;m tired of... | cause Im tired of you big bitches coming for ... | ( , cause, I, m, tired, of, you, big, bitches,... | [be, tired, big, bitch, come, skinny, girl] | be tired big bitch come skinny girl | . 8 8 | 1 | &quot; &amp;amp; you might not get ya bitch back &amp;amp; ... | amp you might not get ya bitch back amp thats... | ( , amp, you, might, not, get, ya, bitch, back... | [amp, amp, s] | amp amp s | . 9 9 | 1 | &quot; @rhythmixx_ :hobbies include: fighting Maria... | hobbies include fighting Mariam bitch | ( , hobbies, include, fighting, Mariam, bitch) | [hobby, include, fight, mariam, bitch] | hobby include fight mariam bitch | . Now that my tweets have been cleaned I create a corpus of tweets. To do so, I use Gensim to apply a dictionary to my tokens and to set some boundaries within which is not necessary to keep the tokens. More specifically, I&#39;ll not consider tokens that appear in less than 10 tweets . !pip install -qq -U gensim . |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24.2MB 165kB/s . from gensim.corpora.dictionary import Dictionary from gensim.models.tfidfmodel import TfidfModel from gensim.models.lsimodel import LsiModel . dictionary = Dictionary(data[&#39;tokens&#39;]) . dictionary.filter_extremes(no_below=10, no_above=0.5) . Now I can also see the corresponding ID for each token in the dictionary, which helps to make sense out of the series of number that I&#39;d have otherwise . list(dictionary.token2id.items())[:25] . [(&#39;amp&#39;, 0), (&#39;clean&#39;, 1), (&#39;complain&#39;, 2), (&#39;house&#39;, 3), (&#39;man&#39;, 4), (&#39;trash&#39;, 5), (&#39;woman&#39;, 6), (&#39;1st&#39;, 7), (&#39;bad&#39;, 8), (&#39;boy&#39;, 9), (&#39;cuffin&#39;, 10), (&#39;hoe&#39;, 11), (&#39;place&#39;, 12), (&#39;bitch&#39;, 13), (&#39;confuse&#39;, 14), (&#39;cry&#39;, 15), (&#39;dawg&#39;, 16), (&#39;fuck&#39;, 17), (&#39;shit&#39;, 18), (&#39;start&#39;, 19), (&#39;look&#39;, 20), (&#39;tranny&#39;, 21), (&#39;hear&#39;, 22), (&#39;tell&#39;, 23), (&#39;true&#39;, 24)] . Now that the dictionary is created, I can get the corpus, which is a list of tuples, with word-ids and the number of their occurrence in documents . corpus = [dictionary.doc2bow(doc) for doc in data[&#39;tokens&#39;]] . corpus [:18] . [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)], [(20, 1), (21, 1)], [(13, 1), (18, 1), (22, 1), (23, 1), (24, 1)], [(11, 1), (17, 1), (18, 1), (25, 1), (26, 1)], [(13, 1), (18, 1), (27, 1), (28, 1), (29, 1), (30, 1)], [(13, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1)], [(0, 2), (37, 1)], [(13, 1), (38, 1), (39, 1)], [(13, 1), (40, 1), (41, 1), (42, 1), (43, 1)], [(13, 1), (44, 2), (45, 1)], [(11, 1), (46, 1), (47, 1), (48, 1), (49, 1)], [(8, 1), (13, 1), (50, 1), (51, 1)], [(13, 1)], [(13, 1), (52, 1), (53, 1)], [(13, 1)], [(13, 1), (54, 1)]] . id_tok = [[(dictionary[id], count) for id, count in line] for line in corpus] print(id_tok[:8]) . [[(&#39;amp&#39;, 1), (&#39;clean&#39;, 1), (&#39;complain&#39;, 1), (&#39;house&#39;, 1), (&#39;man&#39;, 1), (&#39;trash&#39;, 1), (&#39;woman&#39;, 1)], [(&#39;1st&#39;, 1), (&#39;bad&#39;, 1), (&#39;boy&#39;, 1), (&#39;cuffin&#39;, 1), (&#39;hoe&#39;, 1), (&#39;place&#39;, 1)], [(&#39;bitch&#39;, 1), (&#39;confuse&#39;, 1), (&#39;cry&#39;, 1), (&#39;dawg&#39;, 1), (&#39;fuck&#39;, 1), (&#39;shit&#39;, 1), (&#39;start&#39;, 1)], [(&#39;look&#39;, 1), (&#39;tranny&#39;, 1)], [(&#39;bitch&#39;, 1), (&#39;shit&#39;, 1), (&#39;hear&#39;, 1), (&#39;tell&#39;, 1), (&#39;true&#39;, 1)], [(&#39;hoe&#39;, 1), (&#39;fuck&#39;, 1), (&#39;shit&#39;, 1), (&#39;blow&#39;, 1), (&#39;faithful&#39;, 1)], [(&#39;bitch&#39;, 1), (&#39;shit&#39;, 1), (&#39;get&#39;, 1), (&#39;go&#39;, 1), (&#39;hate&#39;, 1), (&#39;sit&#39;, 1)], [(&#39;bitch&#39;, 1), (&#39;be&#39;, 1), (&#39;big&#39;, 1), (&#39;come&#39;, 1), (&#39;girl&#39;, 1), (&#39;skinny&#39;, 1), (&#39;tired&#39;, 1)]] . TF-IDF . tfidf = TfidfModel(corpus) . tfidf_corpus = tfidf[corpus] . from gensim.matutils import corpus2dense . corpus2dense(tfidf_corpus[:10], num_terms=len(dictionary)).T . array([[0.27333793, 0.48495793, 0.49494743, ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. ], ..., [0. , 0. , 0. , ..., 0. , 0. , 0. ], [0.91796744, 0. , 0. , ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. ]], dtype=float32) . &#160;LSA-topic modelling . from gensim.models.tfidfmodel import TfidfModel . lsi_model = LsiModel(tfidf_corpus, num_topics = 60, id2word=dictionary) . lsi_model.print_topics(15) . [(0, &#39;0.916*&#34;bitch&#34; + 0.181*&#34;be&#34; + 0.158*&#34;hoe&#34; + 0.116*&#34;fuck&#34; + 0.092*&#34;get&#34; + 0.081*&#34;ass&#34; + 0.078*&#34;nigga&#34; + 0.066*&#34;pussy&#34; + 0.061*&#34;shit&#34; + 0.056*&#34;know&#34;&#39;), (1, &#39;0.866*&#34;hoe&#34; + -0.302*&#34;bitch&#34; + 0.208*&#34;be&#34; + 0.125*&#34;pussy&#34; + 0.122*&#34;get&#34; + 0.078*&#34;fuck&#34; + 0.073*&#34;love&#34; + 0.072*&#34;nigga&#34; + 0.069*&#34;shit&#34; + 0.066*&#34;know&#34;&#39;), (2, &#39;0.882*&#34;pussy&#34; + -0.301*&#34;hoe&#34; + 0.141*&#34;be&#34; + -0.131*&#34;bitch&#34; + 0.107*&#34;fuck&#34; + 0.100*&#34;eat&#34; + 0.078*&#34;get&#34; + 0.077*&#34;ass&#34; + 0.076*&#34;nigga&#34; + 0.067*&#34;trash&#34;&#39;), (3, &#39;0.568*&#34;be&#34; + 0.489*&#34;trash&#34; + -0.373*&#34;pussy&#34; + -0.295*&#34;hoe&#34; + -0.176*&#34;bitch&#34; + 0.162*&#34;fuck&#34; + 0.148*&#34;shit&#34; + 0.106*&#34;get&#34; + 0.105*&#34;ass&#34; + 0.100*&#34;nigga&#34;&#39;), (4, &#39;0.731*&#34;trash&#34; + -0.631*&#34;be&#34; + 0.118*&#34;fuck&#34; + 0.095*&#34;s&#34; + 0.093*&#34;white&#34; + 0.091*&#34;hoe&#34; + -0.064*&#34;loyal&#34; + 0.046*&#34;bitch&#34; + 0.044*&#34;love&#34; + 0.040*&#34;pussy&#34;&#39;), (5, &#39;0.697*&#34;fuck&#34; + -0.394*&#34;trash&#34; + -0.304*&#34;be&#34; + 0.216*&#34;ass&#34; + 0.210*&#34;nigga&#34; + -0.168*&#34;pussy&#34; + 0.130*&#34;faggot&#34; + 0.127*&#34;get&#34; + -0.109*&#34;hoe&#34; + -0.109*&#34;bitch&#34;&#39;), (6, &#39;0.690*&#34;get&#34; + -0.530*&#34;fuck&#34; + -0.199*&#34;be&#34; + 0.144*&#34;s&#34; + 0.131*&#34;lol&#34; + -0.129*&#34;trash&#34; + 0.125*&#34;ass&#34; + 0.102*&#34;nigga&#34; + 0.102*&#34;bad&#34; + -0.102*&#34;hoe&#34;&#39;), (7, &#39;-0.622*&#34;get&#34; + -0.336*&#34;fuck&#34; + 0.333*&#34;ass&#34; + 0.317*&#34;love&#34; + 0.291*&#34;nigga&#34; + 0.272*&#34;s&#34; + 0.128*&#34;know&#34; + 0.103*&#34;lol&#34; + 0.100*&#34;shit&#34; + 0.098*&#34;faggot&#34;&#39;), (8, &#39;0.771*&#34;love&#34; + -0.410*&#34;nigga&#34; + -0.383*&#34;ass&#34; + 0.160*&#34;s&#34; + 0.115*&#34;fuck&#34; + 0.074*&#34;bad&#34; + 0.072*&#34;faggot&#34; + 0.067*&#34;know&#34; + -0.063*&#34;yo&#34; + 0.060*&#34;bird&#34;&#39;), (9, &#39;-0.515*&#34;love&#34; + 0.496*&#34;s&#34; + -0.328*&#34;ass&#34; + -0.308*&#34;nigga&#34; + 0.280*&#34;faggot&#34; + 0.228*&#34;know&#34; + 0.158*&#34;lol&#34; + -0.145*&#34;get&#34; + 0.138*&#34;bad&#34; + 0.114*&#34;shit&#34;&#39;), (10, &#39;-0.719*&#34;faggot&#34; + -0.448*&#34;lol&#34; + 0.437*&#34;s&#34; + 0.171*&#34;bad&#34; + 0.100*&#34;shit&#34; + 0.090*&#34;nigga&#34; + -0.073*&#34;ass&#34; + 0.069*&#34;go&#34; + 0.050*&#34;fuck&#34; + 0.047*&#34;amp&#34;&#39;), (11, &#39;-0.754*&#34;lol&#34; + 0.537*&#34;faggot&#34; + -0.174*&#34;shit&#34; + 0.161*&#34;nigga&#34; + 0.133*&#34;know&#34; + 0.118*&#34;s&#34; + -0.071*&#34;look&#34; + -0.070*&#34;niggah&#34; + 0.069*&#34;get&#34; + -0.063*&#34;bird&#34;&#39;), (12, &#39;0.855*&#34;know&#34; + -0.367*&#34;s&#34; + -0.213*&#34;ass&#34; + -0.184*&#34;faggot&#34; + 0.147*&#34;nigga&#34; + 0.060*&#34;real&#34; + -0.058*&#34;yo&#34; + 0.055*&#34;let&#34; + -0.044*&#34;look&#34; + -0.043*&#34;get&#34;&#39;), (13, &#39;0.567*&#34;shit&#34; + -0.476*&#34;nigga&#34; + -0.336*&#34;s&#34; + -0.327*&#34;lol&#34; + 0.238*&#34;ass&#34; + 0.164*&#34;talk&#34; + 0.161*&#34;look&#34; + 0.134*&#34;niggas&#34; + 0.108*&#34;hate&#34; + -0.101*&#34;be&#34;&#39;), (14, &#39;-0.549*&#34;ass&#34; + 0.520*&#34;shit&#34; + 0.485*&#34;nigga&#34; + -0.269*&#34;know&#34; + 0.125*&#34;faggot&#34; + 0.119*&#34;talk&#34; + -0.110*&#34;s&#34; + -0.094*&#34;bad&#34; + 0.092*&#34;go&#34; + -0.077*&#34;yo&#34;&#39;)] . The trained model can now transform the corpus . lsi_model[corpus][0] . [(0, 0.0987224466777785), (1, 0.1234724246847981), (2, 0.13128738504656454), (3, 0.5965762608239694), (4, 0.7826544827302331), (5, -0.2992306656536428), (6, -0.03320923544890143), (7, -0.036902748227221074), (8, 0.025247280546842638), (9, -0.004210336492807684), (10, 0.0032020703709961873), (11, 0.03090240296909816), (12, 0.026733300178114965), (13, 0.026793976000511185), (14, -0.014529167643620309), (15, -0.014822640742846907), (16, 0.06934869720481203), (17, 0.2397651659159507), (18, 0.07392616656370034), (19, 0.019978193876570245), (20, -0.004488622056742405), (21, 0.13048048320736774), (22, 0.15153470373210354), (23, 0.11248850395039513), (24, 0.14400650692129138), (25, 0.033055874125467316), (26, 0.07688721104511985), (27, 0.14451851247286746), (28, 0.7390647734653238), (29, 0.29879071575057514), (30, 0.45086184371600363), (31, 0.0019295106794598674), (32, 0.07883828799658577), (33, 0.15423256779014516), (34, 0.021549447745111982), (35, 0.13735462270643517), (36, 0.1323132598045583), (37, 0.07741477982623739), (38, -0.1145492138543538), (39, 0.008484886037862675), (40, 0.030774065989930374), (41, 0.1505902488058594), (42, -0.10489332424140091), (43, -0.22458006532397773), (44, 0.17460249647530726), (45, 0.2978604878320638), (46, -0.6795053496132705), (47, -0.25539387533039554), (48, -0.25052169139017566), (49, 0.25388623014675804), (50, -0.05165297386761249), (51, 0.0798464608598328), (52, 0.029485003808645216), (53, -0.044057104425861436), (54, 0.12006503236665324), (55, -0.23164834606653045), (56, 0.02661458520820258), (57, 0.08603720061438506), (58, 0.08307227865935665), (59, 0.01366899631150623)] . Finally, I can load the MatrixSimilarity . lsi_corpus = lsi_model[tfidf_corpus] . from gensim.similarities import MatrixSimilarity # Create the document-topic-matrix document_topic_matrix = MatrixSimilarity(lsi_corpus) document_topic_matrix_ix = document_topic_matrix.index . 2. Explore and compare the 2 &quot;classes of interest&quot; - hate speech vs offensive language. . The first thing to do to conduct this analysis is to create the sub-data frames from the original one, remembering that: . 0 - hate speech, 1 - offensive language, 2 - neither . Can you see differences by using simple count-based approaches? . data_hate = data[data[&quot;class&quot;] == 0] data_offensive = data[data[&quot;class&quot;] == 1] . I will calculate the most common 15 words in both data frames and see if there are any obvious differences. I&#39;ll took as source of words the &#39;tokens&#39; of my data frame . import itertools import collections . Let&#39;s look at the most common words from the hate df . words_hate = itertools.chain(*data_hate[&#39;tokens&#39;]) . counts_hate = collections.Counter(words_hate) . counts_hate.most_common(15) . [] . Now I repeat the process for the offensive df . words_offensive = itertools.chain(*data_offensive[&#39;tokens&#39;]) . counts_offensive = collections.Counter(words_offensive) . counts_offensive.most_common(15) . [(&#39;bitch&#39;, 10766), (&#39;hoe&#39;, 3972), (&#39;be&#39;, 2993), (&#39;pussy&#39;, 2133), (&#39;fuck&#39;, 1555), (&#39;get&#39;, 1553), (&#39;ass&#39;, 1433), (&#39;shit&#39;, 1188), (&#39;nigga&#39;, 1109), (&#39;s&#39;, 982), (&#39;go&#39;, 783), (&#39;know&#39;, 780), (&#39;lol&#39;, 709), (&#39;niggas&#39;, 662), (&#39;love&#39;, 638)] . From the most common words it&#39;s possible to notice 2 things: . Exclusind stop words in the filtering part would have been better | Although the most common sware words in the two df are similar, in the hate one it&#39;s possible to notice how the most used ones refer to sexuality or rance, which fits with the category. While in the offensive df, we can notice how &#39;more general&#39; words (so no related to sexual orientation or race) are used | Can you identify themes (aka clusters / topics) that are specific for one class or another? . from gensim.models import LdaMulticore import gensim . pip install pyldavis . import pyLDAvis.gensim . %matplotlib inline pyLDAvis.enable_notebook() . Now I&#39;ll try to visually identify some unique terms in the 2 data sets. I start with the offensive speech one . id2word_offensive = Dictionary(data_offensive[&quot;tokens&quot;]) # Create Corpus: Term Document Frequency corpus_offensive = [id2word_offensive.doc2bow(text) for text in data_offensive[&quot;tokens&quot;]] # Build LDA model lda_model_offensive = gensim.models.ldamodel.LdaModel(corpus=corpus_offensive, id2word=id2word_offensive, num_topics=8, random_state=18, chunksize=10, passes=10) . lda_model_offensive.print_topics() . [(0, &#39;0.274*&#34;hoe&#34; + 0.035*&#34;bad&#34; + 0.035*&#34;talk&#34; + 0.027*&#34;people&#34; + 0.023*&#34;let&#34; + 0.022*&#34;like&#34; + 0.019*&#34;lie&#34; + 0.019*&#34;boy&#34; + 0.019*&#34;real&#34; + 0.016*&#34;crazy&#34;&#39;), (1, &#39;0.190*&#34;pussy&#34; + 0.062*&#34;wit&#34; + 0.051*&#34;think&#34; + 0.041*&#34;day&#34; + 0.031*&#34;time&#34; + 0.015*&#34;pop&#34; + 0.014*&#34;change&#34; + 0.013*&#34;gettin&#34; + 0.012*&#34;bitches&#34; + 0.011*&#34;ya&#34;&#39;), (2, &#39;0.133*&#34;bitch&#34; + 0.082*&#34;fuck&#34; + 0.039*&#34;u&#34; + 0.033*&#34;need&#34; + 0.026*&#34;stupid&#34; + 0.025*&#34;bout&#34; + 0.018*&#34;n&#34; + 0.018*&#34;dick&#34; + 0.017*&#34;wanna&#34; + 0.017*&#34;little&#34;&#39;), (3, &#39;0.035*&#34;thing&#34; + 0.033*&#34;ho&#34; + 0.026*&#34;jus&#34; + 0.025*&#34;week&#34; + 0.021*&#34;nasty&#34; + 0.017*&#34;sleep&#34; + 0.016*&#34;thot&#34; + 0.016*&#34;den&#34; + 0.016*&#34;roll&#34; + 0.015*&#34;trick&#34;&#39;), (4, &#39;0.221*&#34;bitch&#34; + 0.075*&#34;ass&#34; + 0.045*&#34;niggas&#34; + 0.027*&#34;trash&#34; + 0.017*&#34;tho&#34; + 0.014*&#34;da&#34; + 0.014*&#34;new&#34; + 0.012*&#34;fat&#34; + 0.011*&#34;smh&#34; + 0.011*&#34;old&#34;&#39;), (5, &#39;0.164*&#34;bitch&#34; + 0.120*&#34;be&#34; + 0.060*&#34;nigga&#34; + 0.058*&#34;get&#34; + 0.037*&#34;go&#34; + 0.029*&#34;know&#34; + 0.026*&#34;want&#34; + 0.021*&#34;girl&#34; + 0.019*&#34;love&#34; + 0.018*&#34;fucking&#34;&#39;), (6, &#39;0.109*&#34;shit&#34; + 0.060*&#34;look&#34; + 0.057*&#34;lol&#34; + 0.049*&#34;yo&#34; + 0.037*&#34;dat&#34; + 0.032*&#34;good&#34; + 0.023*&#34;lmao&#34; + 0.023*&#34;tryna&#34; + 0.022*&#34;life&#34; + 0.022*&#34;tweet&#34;&#39;), (7, &#39;0.086*&#34;s&#34; + 0.047*&#34;fuckin&#34; + 0.031*&#34;amp&#34; + 0.030*&#34;white&#34; + 0.024*&#34;ugly&#34; + 0.021*&#34;retarded&#34; + 0.020*&#34;ghetto&#34; + 0.020*&#34;head&#34; + 0.020*&#34;lil&#34; + 0.020*&#34;stop&#34;&#39;)] . graph_offensive = pyLDAvis.gensim.prepare(lda_model_offensive, corpus_offensive, dictionary=lda_model_offensive.id2word) graph_offensive . Now I do the same for the hate speech df . id2word_hate = Dictionary(data_hate[&quot;tokens&quot;]) # Create Corpus: Term Document Frequency corpus_hate = [id2word_hate.doc2bow(text) for text in data_hate[&quot;tokens&quot;]] # Build LDA model lda_model_hate = gensim.models.ldamodel.LdaModel(corpus=corpus_hate, id2word=id2word_hate, num_topics=8, random_state=18, chunksize=10, passes=10) . lda_model_hate.print_topics() . [(0, &#39;0.099*&#34;nigga&#34; + 0.055*&#34;retard&#34; + 0.046*&#34;look&#34; + 0.032*&#34;ugly&#34; + 0.028*&#34;kill&#34; + 0.023*&#34;lol&#34; + 0.021*&#34;life&#34; + 0.020*&#34;person&#34; + 0.019*&#34;coon&#34; + 0.016*&#34;stfu&#34;&#39;), (1, &#39;0.136*&#34;faggot&#34; + 0.079*&#34;ass&#34; + 0.045*&#34;get&#34; + 0.042*&#34;pussy&#34; + 0.036*&#34;know&#34; + 0.030*&#34;yo&#34; + 0.027*&#34;talk&#34; + 0.026*&#34;good&#34; + 0.021*&#34;fat&#34; + 0.021*&#34;think&#34;&#39;), (2, &#39;0.097*&#34;fuck&#34; + 0.092*&#34;hoe&#34; + 0.083*&#34;fucking&#34; + 0.047*&#34;hate&#34; + 0.046*&#34;try&#34; + 0.029*&#34;people&#34; + 0.022*&#34;gay&#34; + 0.019*&#34;work&#34; + 0.018*&#34;black&#34; + 0.014*&#34;niccas&#34;&#39;), (3, &#39;0.033*&#34;want&#34; + 0.032*&#34;real&#34; + 0.030*&#34;little&#34; + 0.030*&#34;thing&#34; + 0.028*&#34;wetback&#34; + 0.027*&#34;shoot&#34; + 0.021*&#34;die&#34; + 0.018*&#34;redneck&#34; + 0.017*&#34;complain&#34; + 0.016*&#34;eat&#34;&#39;), (4, &#39;0.088*&#34;nigger&#34; + 0.048*&#34;man&#34; + 0.034*&#34;stupid&#34; + 0.030*&#34;day&#34; + 0.022*&#34;call&#34; + 0.020*&#34;woman&#34; + 0.017*&#34;gook&#34; + 0.014*&#34;folk&#34; + 0.014*&#34;car&#34; + 0.014*&#34;right&#34;&#39;), (5, &#39;0.102*&#34;white&#34; + 0.073*&#34;trash&#34; + 0.027*&#34;tell&#34; + 0.026*&#34;see&#34; + 0.021*&#34;beaner&#34; + 0.020*&#34;buy&#34; + 0.019*&#34;niggah&#34; + 0.019*&#34;stop&#34; + 0.019*&#34;girl&#34; + 0.018*&#34;racist&#34;&#39;), (6, &#39;0.085*&#34;fag&#34; + 0.058*&#34;s&#34; + 0.034*&#34;cunt&#34; + 0.027*&#34;come&#34; + 0.021*&#34;ill&#34; + 0.020*&#34;wanna&#34; + 0.018*&#34;bad&#34; + 0.018*&#34;u&#34; + 0.013*&#34;bc&#34; + 0.012*&#34;break&#34;&#39;), (7, &#39;0.215*&#34;bitch&#34; + 0.070*&#34;be&#34; + 0.059*&#34;niggas&#34; + 0.026*&#34;shit&#34; + 0.022*&#34;big&#34; + 0.018*&#34;amp&#34; + 0.017*&#34;face&#34; + 0.017*&#34;find&#34; + 0.017*&#34;queer&#34; + 0.014*&#34;hot&#34;&#39;)] . graph_hate = pyLDAvis.gensim.prepare(lda_model_hate, corpus_hate, dictionary=lda_model_hate.id2word) graph_hate . As identified in the count based approach, a difference between the 2 sub df is not so easy to detect in a straightforward way. However, as mentioned above, also here we can detected some differences in the words distribution: . Hate List: the first 5 topics are similar in marginal topic distribution. It interesting to notice that baside topic 2, in all the others the most used words are either referring to sexuality (faggot, fag) or race (nigga, white, nigger). In topic 2, and also 5 since it&#39;s the one closer to the PC1 line, the most used words are more &#39;colloquial&#39; and less hateful (fuck, bitch). Those one could fit better in the offensive category | Offensive List: here we have more homogeneous results in the different topic. Indee, the vast majority of topics the most used words are fuck, pussy, bithc and so on. So offensive words but not hateful in terms of discriminatory in relation to a specific sexuality or race. Nonetheless, also in here we see the presence of hate-speech related words, just less often. So, the distinction between the 2 is not so easy to spot in a definite way | 3. Build an ML model that can predict hate speech . As first thing we need to import the required packages and then input the data in the train split test . from sklearn.pipeline import Pipeline from sklearn.metrics import classification_report from sklearn.model_selection import train_test_split . Then we set the label to be equal to class, since this is the variable for which we want to train the model . y = data[&#39;class&#39;] . X_train, X_test, y_train, y_test = train_test_split(data[&quot;token_string&quot;], y, test_size=0.2, random_state=18) . X_train . 4877 get hun be text u 8896 dumb little broad fuck bitch 10394 get bad bitch bake cookie 7188 special time place decaf coffee trash familys ... 4027 stop look porn fag ... 18674 wonder fan la feel charlie brown lucy pull bal... 5294 picture make look fag lol 16305 bitch tell nigga mine ready tell tf level shit 1726 jose fucking mean damn bitch lol fuck 2885 realize dat Name: token_string, Length: 19826, dtype: object . I will start with testing a model that uses Count Vectorizer . from sklearn.feature_extraction.text import CountVectorizer vectorizer = CountVectorizer() X_train_vec_1 = vectorizer.fit_transform(X_train) . from sklearn.linear_model import LogisticRegression model = LogisticRegression(max_iter=2000) . model.fit(X_train_vec_1, y_train) . LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=2000, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0, warm_start=False) . X_test_vec_1 = vectorizer.transform(X_test) . model.score(X_test_vec, y_test) . 0.886624974783135 . Now I will try to use TfidfVectorizer . from sklearn.feature_extraction.text import TfidfVectorizer vectorizer_2 = TfidfVectorizer() X_train_vec_2 = vectorizer_2.fit_transform(X_train) . from sklearn.linear_model import LogisticRegression model = LogisticRegression(max_iter=2000) . model.fit(X_train_vec_2, y_train) . LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=2000, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0, warm_start=False) . X_test_vec_2 = vectorizer_2.transform(X_test) . model.score(X_test_vec_2, y_test) . 0.9033689731692556 . So the TfidfVectorizer is more accurate. To have further proof let&#39;s try to obtain a report from both TfidfVectorizer and CountVectorizer . TfidfVectorizer . pipeline_test_1 = Pipeline( steps=[ (&quot;count_vec&quot;, TfidfVectorizer()), (&quot;model&quot;, LogisticRegression(max_iter=2000)), ]) pipeline_test_1.fit(X_train, y_train) y_pred = pipeline_test_1.predict(X_test) cr = classification_report(y_test, y_pred) print(cr) . precision recall f1-score support 0 0.54 0.18 0.27 285 1 0.92 0.97 0.94 3829 2 0.86 0.86 0.86 843 accuracy 0.90 4957 macro avg 0.77 0.67 0.69 4957 weighted avg 0.89 0.90 0.89 4957 . CountVectorizer . pipeline_test_2 = Pipeline( steps=[ (&quot;count_vec&quot;, CountVectorizer()), (&quot;rand_forest&quot;, LogisticRegression(max_iter=2000)), ]) pipeline_test_2.fit(X_train, y_train) y_pred = pipeline_test_2.predict(X_test) cr = classification_report(y_test, y_pred) print(cr) . precision recall f1-score support 0 0.42 0.18 0.25 285 1 0.93 0.95 0.94 3829 2 0.84 0.89 0.87 843 accuracy 0.90 4957 macro avg 0.73 0.68 0.69 4957 weighted avg 0.88 0.90 0.89 4957 . Also this further test has proven that TfidfVectorizer offers better results overall. It&#39;s worth mentioning that by using CountVectorizer the accuracy of predicting &#39;offensive&#39; speech is higher. On the other hand, the predictions regardin &#39;hate&#39; speech are way worse with this model. . Overall, both model seem to perfrom good (and suprisingly close to best result achieved mentioned in the assignment) when it comes to detecting offensive speech. The performance is accebtable in the detection of regular language. When it come to defining hate speech, both models perform quite bad, with a maximum precision record of 54% . %%shell jupyter nbconvert --to html /content/Mandatory_Assignment_22.ipynb . [NbConvertApp] Converting notebook /content/Mandatory_Assignment_22.ipynb to html [NbConvertApp] Writing 2423402 bytes to /content/Mandatory_Assignment_22.html . .",
            "url": "https://rjuro.github.io/fastpages_test/jupyter/2020/11/12/My-First-Post.html",
            "relUrl": "/jupyter/2020/11/12/My-First-Post.html",
            "date": " â€¢ Nov 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "This and that",
            "content": ". # load the dataset from GitHub - original source penguins = pd.read_csv(&quot;https://github.com/allisonhorst/palmerpenguins/raw/5b5891f01b52ae26ad8cb9755ec93672f49328a8/data/penguins_size.csv&quot;) . . species_short island culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g sex . 0 Adelie | Torgersen | 39.1 | 18.7 | 181.0 | 3750.0 | MALE | . 1 Adelie | Torgersen | 39.5 | 17.4 | 186.0 | 3800.0 | FEMALE | . 2 Adelie | Torgersen | 40.3 | 18.0 | 195.0 | 3250.0 | FEMALE | . 4 Adelie | Torgersen | 36.7 | 19.3 | 193.0 | 3450.0 | FEMALE | . 5 Adelie | Torgersen | 39.3 | 20.6 | 190.0 | 3650.0 | MALE | . penguins = penguins.dropna() penguins.species_short.value_counts() . Adelie 146 Gentoo 120 Chinstrap 68 Name: species_short, dtype: int64 . . &lt;seaborn.axisgrid.PairGrid at 0x7fe195674c18&gt; .",
            "url": "https://rjuro.github.io/fastpages_test/fastpages/jupyter/2020/11/12/Me-testing-stuff.html",
            "relUrl": "/fastpages/jupyter/2020/11/12/Me-testing-stuff.html",
            "date": " â€¢ Nov 12, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.â†© . 2. This is the other footnote. You can even have a link!â†© .",
            "url": "https://rjuro.github.io/fastpages_test/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " â€¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a â€œlevel 1 headingâ€ in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Hereâ€™s a footnote 1. Hereâ€™s a horizontal rule: . . Lists . Hereâ€™s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes â€¦andâ€¦ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.Â &#8617; . |",
            "url": "https://rjuro.github.io/fastpages_test/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " â€¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.Â &#8617; . |",
          "url": "https://rjuro.github.io/fastpages_test/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ â€œsitemap.xmlâ€ | absolute_url }} | .",
          "url": "https://rjuro.github.io/fastpages_test/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}